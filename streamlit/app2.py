import streamlit as st
import pandas as pd
import numpy as np
import joblib
import pickle
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="House Price Prediction",
    page_icon="üè°",
    layout="wide"
)

st.markdown("""
<style>
    .main-header {
        font-size: 2.2rem;
        font-weight: 700;
        color: #2D3748;
        text-align: center;
        margin-bottom: 1.5rem;
    }
    
    .section-header {
        font-size: 1.5rem;
        font-weight: 600;
        color: #4A5568;
        margin-top: 1.5rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #E2E8F0;
    }
    
    .upload-box {
        border: 2px dashed #CBD5E0;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        margin: 1rem 0;
    }
    
    .step-box {
        background-color: #F7FAFC;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #4299E1;
    }
    
    .warning-box {
        background-color: #FEF3C7;
        border-left: 4px solid #F59E0B;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# –°–Ω–∞—á–∞–ª–∞ –ø–æ–∫–∞–∂–µ–º –¥–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
st.sidebar.write("üîß –î–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")

@st.cache_resource
def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤
    possible_files = [
        "ml_baseline_rfr.pkl",
        "./ml_baseline_rfr.pkl",
        "/mount/src/your-repo-name/ml_baseline_rfr.pkl",  # –ø—É—Ç—å –Ω–∞ Streamlit Cloud
    ]
    
    for model_file in possible_files:
        try:
            st.sidebar.write(f"–ü—Ä–æ–±—É—é –∑–∞–≥—Ä—É–∑–∏—Ç—å: {model_file}")
            
            if os.path.exists(model_file):
                st.sidebar.success(f"‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {model_file}")
                st.sidebar.write(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {os.path.getsize(model_file) / 1024 / 1024:.2f} MB")
                
                try:
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º joblib
                    model = joblib.load(model_file)
                    st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ joblib")
                    return model, "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ"
                except Exception as e:
                    st.sidebar.warning(f"Joblib –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {str(e)[:100]}")
                    
                    try:
                        # –ü—Ä–æ–±—É–µ–º pickle
                        with open(model_file, 'rb') as f:
                            model = pickle.load(f)
                        st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ pickle")
                        return model, "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ"
                    except Exception as e2:
                        st.sidebar.warning(f"Pickle –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {str(e2)[:100]}")
                        
                        try:
                            # –ü—Ä–æ–±—É–µ–º pickle —Å latin1
                            with open(model_file, 'rb') as f:
                                model = pickle.load(f, encoding='latin1')
                            st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ pickle (latin1)")
                            return model, "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ"
                        except Exception as e3:
                            st.sidebar.error(f"–í—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏: {str(e3)[:100]}")
            else:
                st.sidebar.info(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_file}")
                
        except Exception as e:
            st.sidebar.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {model_file}: {str(e)[:100]}")
    
    # –ü–æ–∫–∞–∂–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    st.sidebar.write("üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
    try:
        files = os.listdir('.')
        for file in files:
            st.sidebar.write(f"  - {file}")
    except Exception as e:
        st.sidebar.error(f"–ù–µ –º–æ–≥—É –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {e}")
    
    return None, "‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª 'ml_baseline_rfr.pkl' –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è."

def preprocess_data_simple(df):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    df = df.copy()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º Id
    if 'Id' in df.columns:
        ids = df['Id'].copy()
        df = df.drop('Id', axis=1)
    else:
        ids = pd.Series(range(1, len(df) + 1), name='Id')
    
    # –£–¥–∞–ª—è–µ–º SalePrice –µ—Å–ª–∏ –µ—Å—Ç—å
    if 'SalePrice' in df.columns:
        df = df.drop('SalePrice', axis=1)
    
    try:
        # –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        categorical_cols = df.select_dtypes(include=['object']).columns
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        for col in numeric_cols:
            if df[col].isnull().any():
                df[col] = df[col].fillna(df[col].median() if not df[col].isnull().all() else 0)
        
        for col in categorical_cols:
            if df[col].isnull().any():
                if df[col].notna().any():
                    mode_val = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'
                    df[col] = df[col].fillna(mode_val)
                else:
                    df[col] = df[col].fillna('Unknown')
        
        # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        from sklearn.preprocessing import OneHotEncoder, StandardScaler
        
        if len(categorical_cols) > 0:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π one-hot –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            important_cats = ['MSZoning', 'Neighborhood', 'HouseStyle', 'KitchenQual', 
                             'SaleType', 'SaleCondition', 'CentralAir']
            
            encoded_dfs = []
            for col in important_cats:
                if col in df.columns:
                    dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)
                    encoded_dfs.append(dummies)
            
            # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            df = df.drop(categorical_cols, axis=1, errors='ignore')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
            if encoded_dfs:
                df = pd.concat([df] + encoded_dfs, axis=1)
        
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (109)
        current_features = df.shape[1]
        
        if current_features > 109:
            df = df.iloc[:, :109]
            st.info(f"‚ÑπÔ∏è –£–º–µ–Ω—å—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å {current_features} –¥–æ 109")
        elif current_features < 109:
            missing_features = 109 - current_features
            for i in range(missing_features):
                df[f'feature_{i}'] = 0
            st.info(f"‚ÑπÔ∏è –î–æ–±–∞–≤–ª–µ–Ω–æ {missing_features} –ø—É—Å—Ç—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        scaler = StandardScaler()
        processed_data = scaler.fit_transform(df)
        
        st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {processed_data.shape[0]} —Å—Ç—Ä–æ–∫, {processed_data.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return processed_data, ids
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return None, None

# –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.markdown("<h1 class='main-header'>üè° –ü—Ä–æ–≥–Ω–æ–∑ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏</h1>", unsafe_allow_html=True)

st.info("""
–≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∂–∏–ª–æ–π –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏.
–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
""")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model, model_message = load_model()

if model is None:
    st.error(model_message)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–º–æ—â—å
    with st.expander("üõ†Ô∏è –ü–æ–º–æ—â—å –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º—ã"):
        st.write("""
        **–ü—Ä–æ–±–ª–µ–º–∞:** –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ Streamlit Cloud.
        
        **–†–µ—à–µ–Ω–∏–µ:**
        1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª `ml_baseline_rfr.pkl` –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –≤–∞—à —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
        2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ (–Ω–µ –≤ –ø–æ–¥–ø–∞–ø–∫–µ)
        3. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ < 200MB
        4. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞ Streamlit Cloud
        
        **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å:**
        ```
        –≤–∞—à-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π/
        ‚îú‚îÄ‚îÄ app.py
        ‚îú‚îÄ‚îÄ ml_baseline_rfr.pkl
        ‚îî‚îÄ‚îÄ requirements.txt
        ```
        """)
    st.stop()

st.success(model_message)

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
with st.expander("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"):
    st.write(f"**–¢–∏–ø –º–æ–¥–µ–ª–∏:** {type(model).__name__}")
    
    if hasattr(model, 'n_features_in_'):
        st.write(f"**–û–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** {model.n_features_in_}")
    elif hasattr(model, 'feature_importances_'):
        st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** {len(model.feature_importances_)}")
    
    if hasattr(model, 'n_estimators'):
        st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤:** {model.n_estimators}")

# –°–µ–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
st.markdown("<h2 class='section-header'>üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</h2>", unsafe_allow_html=True)

st.markdown("""
<div class='upload-box'>
    <h4>üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∞–Ω–Ω—ã–º</h4>
    <p>–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏</p>
    <p><small>–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ House Prices dataset</small></p>
</div>
""", unsafe_allow_html=True)

uploaded_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª",
    type=['csv'],
    key="predict_uploader"
)

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        
        st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("–°—Ç—Ä–æ–∫", df.shape[0])
        with col2:
            st.metric("–°—Ç–æ–ª–±—Ü–æ–≤", df.shape[1])
        with col3:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            st.metric("–ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", len(numeric_cols))
        
        # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
        with st.expander("üëÅÔ∏è –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
            st.dataframe(df.head(10), use_container_width=True)
        
        # –ö–Ω–æ–ø–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        if st.button("üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å", type="primary", use_container_width=True):
            with st.spinner("üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ..."):
                processed_data, ids = preprocess_data_simple(df)
                
                if processed_data is None:
                    st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")
                    st.stop()
                
                st.write(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {processed_data.shape[1]}")
                
                with st.spinner("ü§ñ –î–µ–ª–∞—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è..."):
                    try:
                        predictions = model.predict(processed_data)
                        
                        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —à–∫–∞–ª—ã
                        try:
                            predictions = np.expm1(predictions)
                            st.info("‚ÑπÔ∏è –ü—Ä–∏–º–µ–Ω–µ–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π —à–∫–∞–ª—ã")
                        except:
                            st.info("‚ÑπÔ∏è –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –∏—Å—Ö–æ–¥–Ω–æ–π —à–∫–∞–ª–µ")
                        
                        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        results_df = pd.DataFrame({
                            'Id': ids,
                            'Predicted_Price': predictions.round(2)
                        })
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        st.markdown("<h2 class='section-header'>üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã</h2>", unsafe_allow_html=True)
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("–û–±—ä–µ–∫—Ç–æ–≤", len(predictions))
                        with col2:
                            st.metric("–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞", f"${predictions.mean():,.0f}")
                        with col3:
                            st.metric("–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è", f"${predictions.min():,.0f}")
                        with col4:
                            st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è", f"${predictions.max():,.0f}")
                        
                        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                        if len(predictions) > 1:
                            st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω")
                            st.bar_chart(results_df.set_index('Id')['Predicted_Price'])
                        
                        # –¢–∞–±–ª–∏—Ü–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                        st.subheader("üìã –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
                        st.dataframe(
                            results_df.style.format({'Predicted_Price': '${:,.0f}'}),
                            height=400,
                            use_container_width=True
                        )
                        
                        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                        csv = results_df.to_csv(index=False)
                        st.download_button(
                            label="üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (CSV)",
                            data=csv,
                            file_name=f"house_price_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            use_container_width=True,
                            type="primary"
                        )
                        
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {str(e)}")
                        st.info("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö")
                
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #718096; font-size: 0.9rem;">
    <p><strong>House Price Prediction Tool</strong></p>
    <p>–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å Random Forest –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏</p>
</div>
""", unsafe_allow_html=True)