import streamlit as st
import pandas as pd
import numpy as np
import joblib
import pickle
import os
from datetime import datetime
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.base import BaseEstimator, TransformerMixin
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="House Price Prediction",
    page_icon="üè°",
    layout="wide"
)

st.markdown("""
<style>
    .main-header {
        font-size: 2.2rem;
        font-weight: 700;
        color: #2D3748;
        text-align: center;
        margin-bottom: 1.5rem;
    }
    
    .section-header {
        font-size: 1.5rem;
        font-weight: 600;
        color: #4A5568;
        margin-top: 1.5rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #E2E8F0;
    }
    
    .upload-box {
        border: 2px dashed #CBD5E0;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        margin: 1rem 0;
    }
    
    .step-box {
        background-color: #F7FAFC;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #4299E1;
    }
    
    .warning-box {
        background-color: #FEF3C7;
        border-left: 4px solid #F59E0B;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

EXPECTED_COLUMNS = [
    'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 
    'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',
    'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',
    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',
    'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea',
    'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',
    'PoolArea', 'MiscVal', 'MoSold', 'YrSold',
    
    'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',
    'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',
    'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',
    'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',
    'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',
    'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',
    'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',
    'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence',
    'MiscFeature', 'SaleType', 'SaleCondition'
]

FEATURES_TO_DROP = [
    'Utilities', 'Street', 'PoolArea', 'PoolQC', 'Condition2', 
    'RoofMatl', 'Heating', 'LowQualFinSF', '3SsnPorch', 
    'MiscFeature', 'MiscVal', 'Alley', 'BsmtHalfBath', 
    'BsmtFinSF2', 'LandSlope', 'LandContour', 'YrSold', 'MoSold'
]

class HousePricesSmartImputer(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.stats_ = {}
        self.feature_names_in_ = None
        self.feature_names_out_ = None

    def fit(self, X, y=None):
        X = pd.DataFrame(X)
        self.feature_names_in_ = X.columns.tolist()
        self.feature_names_out_ = X.columns.tolist()
        self.stats_ = {}
        
        if 'LotFrontage' in X.columns and 'Neighborhood' in X.columns:
            self.stats_['lot_medians'] = X.groupby('Neighborhood')['LotFrontage'].median().to_dict()
            self.stats_['lot_overall'] = X['LotFrontage'].median()

        if 'MSZoning' in X.columns and 'MSSubClass' in X.columns:
            mode_series = X.groupby('MSSubClass')['MSZoning'].agg(
                lambda x: x.mode().iat[0] if not x.mode().empty else np.nan
            )
            self.stats_['zoning_modes'] = mode_series.to_dict()
            
            overall_zoning_mode = X['MSZoning'].mode()
            self.stats_['zoning_overall'] = overall_zoning_mode.iat[0] if not overall_zoning_mode.empty else None
            
        return self

    def transform(self, X):
        X = pd.DataFrame(X).copy()

        if 'LotFrontage' in X.columns:
            X['LotFrontage'] = X['LotFrontage'].fillna(X['Neighborhood'].map(self.stats_.get('lot_medians', {})))
            X['LotFrontage'] = X['LotFrontage'].fillna(self.stats_.get('lot_overall'))

        if 'MSZoning' in X.columns:
            X['MSZoning'] = X['MSZoning'].fillna(X['MSSubClass'].map(self.stats_.get('zoning_modes', {})))
            X['MSZoning'] = X['MSZoning'].fillna(self.stats_.get('zoning_overall'))

        if 'GarageYrBlt' in X.columns and 'YearBuilt' in X.columns:
            X['GarageYrBlt'] = X['GarageYrBlt'].fillna(X['YearBuilt'])

        if 'Functional' in X.columns:
            X['Functional'] = X['Functional'].fillna('Typ')

        return X.values

    def get_feature_names_out(self, input_features=None):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è"""
        if input_features is not None:
            return input_features
        elif self.feature_names_out_ is not None:
            return self.feature_names_out_
        else:
            raise ValueError("Feature names not available")

@st.cache_resource
def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    model_file = "ml_ensemble_rfr_lgbm_catb.pkl"
    
    if not os.path.exists(model_file):
        return None, f"‚ùå –§–∞–π–ª '{model_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ."
    
    try:
        model = joblib.load(model_file)
        return model, "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ"
    except:
        try:
            with open(model_file, 'rb') as f:
                model = pickle.load(f)
            return model, "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ"
        except:
            try:
                with open(model_file, 'rb') as f:
                    model = pickle.load(f, encoding='latin1')
                return model, "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
            except Exception as e:
                return None, f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)[:100]}"

def preprocess_simple(df):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è House Prices"""
    df = df.copy()
    
    if 'Id' in df.columns:
        ids = df['Id'].copy()
        df = df.drop('Id', axis=1)
    else:
        ids = pd.Series(range(1, len(df) + 1), name='Id')
    
    if 'SalePrice' in df.columns:
        df = df.drop('SalePrice', axis=1)
    
    try:
        cols_to_drop = [col for col in FEATURES_TO_DROP if col in df.columns]
        if cols_to_drop:
            df = df.drop(columns=cols_to_drop)
            st.info(f"‚ÑπÔ∏è –£–¥–∞–ª–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏: {', '.join(cols_to_drop)}")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if col in df.columns:
                df[col] = df[col].fillna(df[col].median() if df[col].notna().any() else 0)
        
        categorical_cols = df.select_dtypes(include=['object']).columns
        
        if 'Functional' in df.columns:
            df['Functional'] = df['Functional'].fillna('Typ')
        
        if 'GarageYrBlt' in df.columns and 'YearBuilt' in df.columns:
            df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['YearBuilt'])
        
        cols_fillna_0 = [
            'MasVnrArea', 'BsmtFullBath', 'BsmtFinSF1', 'BsmtUnfSF', 
            'TotalBsmtSF', 'GarageCars', 'GarageArea'
        ]
        
        cols_fillna_none = [
            'Fence', 'FireplaceQu', 'GarageType', 'GarageFinish', 
            'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 
            'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType'
        ]
        
        cols_fillna_mode = [
            'MSZoning', 'SaleType', 'KitchenQual', 'Electrical', 
            'Exterior1st', 'Exterior2nd'
        ]
        
        for col in cols_fillna_0:
            if col in df.columns:
                df[col] = df[col].fillna(0)
        
        for col in cols_fillna_none:
            if col in df.columns:
                df[col] = df[col].fillna('None')
        
        for col in cols_fillna_mode:
            if col in df.columns:
                if df[col].notna().any():
                    mode_value = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'
                    df[col] = df[col].fillna(mode_value)
                else:
                    df[col] = df[col].fillna('Unknown')
        
        for col in categorical_cols:
            if col in df.columns and df[col].isna().any():
                if col not in cols_fillna_none + cols_fillna_mode and col != 'Functional':
                    df[col] = df[col].fillna('Unknown')
        
        categorical_cols = df.select_dtypes(include=['object']).columns
        
        if len(categorical_cols) > 0:
            encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
            encoded_data = encoder.fit_transform(df[categorical_cols])
        
            encoded_feature_names = []
            for i, col in enumerate(categorical_cols):
                categories = encoder.categories_[i]
                for category in categories:
                    encoded_feature_names.append(f"{col}_{category}")
            
            encoded_df = pd.DataFrame(encoded_data, columns=encoded_feature_names, index=df.index)
    
            numeric_df = df.select_dtypes(include=[np.number])
            df_processed = pd.concat([numeric_df, encoded_df], axis=1)
        else:
            df_processed = df
    
        base_features = [
            'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',
            'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF',
            'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',
            'BsmtFullBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',
            'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea',
            'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch',
            'MiscVal'
        ]
        
        all_expected_features = []
        
        for feature in base_features:
            all_expected_features.append(feature)
        
        categorical_prefixes = ['MSZoning_', 'Neighborhood_', 'HouseStyle_', 'RoofStyle_', 
                               'Exterior1st_', 'Exterior2nd_', 'Foundation_', 'HeatingQC_',
                               'CentralAir_', 'KitchenQual_', 'Functional_', 'GarageType_',
                               'SaleType_', 'SaleCondition_']
        
        for prefix in categorical_prefixes:
            for suffix in ['Typical', 'Average', 'Good', 'Excellent', 'Fair', 'Poor', 
                          'Y', 'N', 'WD', 'New', 'COD', 'CWD', 'Con', 'ConLw', 'ConLI',
                          'ConLD', 'Oth', 'Normal', 'Abnorml', 'Partial', 'Family',
                          'Alloca', 'AdjLand']:
                all_expected_features.append(f"{prefix}{suffix}")
        
        for feature in all_expected_features:
            if feature not in df_processed.columns:
                df_processed[feature] = 0
        
        if len(df_processed.columns) > 109:
            df_processed = df_processed.iloc[:, :109]
        
        scaler = StandardScaler()
        processed_data = scaler.fit_transform(df_processed)
        
        st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º): {processed_data.shape[0]} —Å—Ç—Ä–æ–∫, {processed_data.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return processed_data, ids
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ—Å—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}")
        return None, None

@st.cache_resource
def create_and_fit_pipeline(_X_train, _y_train):
    """–°–æ–∑–¥–∞–µ—Ç –∏ –æ–±—É—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏"""

    if 'Id' in _X_train.columns:
        _X_train = _X_train.drop('Id', axis=1)
    
    features_to_drop = FEATURES_TO_DROP
    
    cols_fillna_0 = [
        'MasVnrArea', 'BsmtFullBath', 'BsmtFinSF1', 'BsmtUnfSF', 
        'TotalBsmtSF', 'GarageCars', 'GarageArea'
    ]
    
    cols_fillna_none = [
        'Fence', 'FireplaceQu', 'GarageType', 'GarageFinish', 
        'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 
        'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType'
    ]
    
    cols_fillna_mode = [
        'MSZoning', 'SaleType', 'KitchenQual', 'Electrical', 
        'Exterior1st', 'Exterior2nd'
    ]
    
    imputer = ColumnTransformer([
        ('drop_features', 'drop', features_to_drop),
        ('smart_imputer', HousePricesSmartImputer(), 
         ['LotFrontage', 'Neighborhood', 'GarageYrBlt', 'YearBuilt', 'Functional']),
        ('zero', SimpleImputer(strategy='constant', fill_value=0), cols_fillna_0),
        ('none', SimpleImputer(strategy='constant', fill_value='None'), cols_fillna_none),
        ('mode', SimpleImputer(strategy='most_frequent'), cols_fillna_mode)
    ], remainder='passthrough', verbose_feature_names_out=False)
    
    X_imputed = imputer.fit_transform(_X_train)
    feature_names = imputer.get_feature_names_out()
    X_imputed_df = pd.DataFrame(X_imputed, columns=feature_names, index=_X_train.index)
    
    cat_cols = X_imputed_df.select_dtypes(include=['object']).columns.tolist()
    
    split = 4
    col_cat_ohe = [col for col in cat_cols if X_imputed_df[col].nunique() <= split]
    
    col_num = X_imputed_df.select_dtypes(include=['number']).columns.tolist()
    preprocessor = ColumnTransformer(
        transformers=[
            ('one_hot_encoding', OneHotEncoder(handle_unknown='ignore', sparse_output=False), col_cat_ohe),
            ('standard_scaler', StandardScaler(), col_num)
        ],
        verbose_feature_names_out=False,
        remainder='drop'
    )
    
    X_processed = preprocessor.fit_transform(X_imputed_df)
    
    if hasattr(preprocessor, 'get_feature_names_out'):
        feature_names_processed = preprocessor.get_feature_names_out()
    else:
        feature_names_processed = []
        for name, trans, cols in preprocessor.transformers_:
            if trans == 'drop':
                continue
            if hasattr(trans, 'get_feature_names_out'):
                feature_names_processed.extend(trans.get_feature_names_out(cols))
            else:
                feature_names_processed.extend(cols)
    
    if len(feature_names_processed) > 109:
        feature_names_processed = feature_names_processed[:109]
        X_processed = X_processed[:, :109]
    
    return {
        'imputer': imputer,
        'preprocessor': preprocessor,
        'feature_names': feature_names_processed,
        'col_cat_ohe': col_cat_ohe,
        'col_num': col_num
    }

def preprocess_with_pipeline(df, pipeline):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–Ω—ã–º –ø–∞–π–ø–ª–∞–π–Ω–æ–º"""
    df = df.copy()
    
    if 'Id' in df.columns:
        ids = df['Id'].copy()
        df_for_processing = df.drop('Id', axis=1)
    else:
        ids = pd.Series(range(1, len(df) + 1), name='Id')
        df_for_processing = df.copy()
    
    if 'SalePrice' in df_for_processing.columns:
        df_for_processing = df_for_processing.drop('SalePrice', axis=1)
    
    try:
        progress_bar = st.progress(0)
        
        progress_bar.progress(20)
        with st.spinner("üîß –®–∞–≥ 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π..."):
            df_imputed = pipeline['imputer'].transform(df_for_processing)
            feature_names = pipeline['imputer'].get_feature_names_out()
            df_imputed = pd.DataFrame(df_imputed, columns=feature_names, index=df_for_processing.index)
        
        progress_bar.progress(50)
        with st.spinner("üîß –®–∞–≥ 2: –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤..."):
            df_processed = pipeline['preprocessor'].transform(df_imputed)
        
        if df_processed.shape[1] > 109:
            df_processed = df_processed[:, :109]
        elif df_processed.shape[1] < 109:
            zeros_to_add = 109 - df_processed.shape[1]
            df_processed = np.hstack([df_processed, np.zeros((df_processed.shape[0], zeros_to_add))])
        
        progress_bar.progress(100)
        st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {df_processed.shape[0]} —Å—Ç—Ä–æ–∫, {df_processed.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return df_processed, ids
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return None, None

st.markdown("<h1 class='main-header'>üè° –ü—Ä–æ–≥–Ω–æ–∑ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏</h1>", unsafe_allow_html=True)

model, model_message = load_model()

if model is None:
    st.error(model_message)
    st.stop()

st.success(model_message)

st.markdown("<h2 class='section-header'>üìö –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ</h2>", unsafe_allow_html=True)

st.markdown("""
<div class='upload-box'>
    –î–ª—è –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π CSV —Ñ–∞–π–ª (—Å –∫–æ–ª–æ–Ω–∫–æ–π 'SalePrice').<br>
    –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç —Å–æ–∑–¥–∞—Ç—å —Ç–æ—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏, –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏.
</div>
""", unsafe_allow_html=True)

uploaded_train_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π CSV —Ñ–∞–π–ª",
    type=['csv'],
    key="train_uploader"
)

if uploaded_train_file is not None:
    with st.spinner("üì• –ó–∞–≥—Ä—É–∂–∞—é —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ..."):
        try:
            train_df = pd.read_csv(uploaded_train_file)
            
            if 'SalePrice' not in train_df.columns:
                st.error("‚ùå –í —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 'SalePrice'")
            else:
                st.success(f"‚úÖ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {train_df.shape[0]} —Å—Ç—Ä–æ–∫, {train_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
                
                X_train = train_df.drop('SalePrice', axis=1)
                y_train = train_df['SalePrice']
                
                with st.spinner("üéØ –°–æ–∑–¥–∞—é –∏ –æ–±—É—á–∞—é –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏..."):
                    try:
                        pipeline = create_and_fit_pipeline(X_train, y_train)
                        
                        st.session_state['pipeline'] = pipeline
                        st.session_state['pipeline_ready'] = True
                        st.session_state['train_size'] = len(train_df)
                        
                        st.success(f"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ –æ–±—É—á–µ–Ω –Ω–∞ {len(train_df)} –ø—Ä–∏–º–µ—Ä–∞—Ö!")
                        
                        with st.expander("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–π–ø–ª–∞–π–Ω–µ"):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("OHE –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", len(pipeline['col_cat_ohe']))
                            with col2:
                                st.metric("–ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", len(pipeline['col_num']))
                            with st.container():
                                st.write(f"**–í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:** {len(pipeline['feature_names'])}")
                                st.write(f"**–ú–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç:** 109 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                            
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞: {str(e)}")
                        st.info("‚ÑπÔ∏è –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
                        st.session_state['pipeline_ready'] = False
                        
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")

if 'pipeline_ready' not in st.session_state or not st.session_state['pipeline_ready']:
    st.markdown("""
    <div class='warning-box'>
    <strong>‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ:</strong> –ü–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω. –î–ª—è –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.<br>
    –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö.
    </div>
    """, unsafe_allow_html=True)
    
    st.session_state['use_simple_processing'] = True

st.markdown("<h2 class='section-header'>üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</h2>", unsafe_allow_html=True)

st.markdown("""
<div class='upload-box'>
    –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.<br>
    <small>–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö House Prices</small>
</div>
""", unsafe_allow_html=True)

uploaded_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è",
    type=['csv'],
    key="predict_uploader"
)

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        
        st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("–°—Ç—Ä–æ–∫", df.shape[0])
        with col2:
            st.metric("–°—Ç–æ–ª–±—Ü–æ–≤", df.shape[1])
        with col3:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            st.metric("–ß–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫", len(numeric_cols))
        
        with st.expander("üëÅÔ∏è –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–∞–Ω–Ω—ã–µ"):
            st.dataframe(df.head())
        
        if st.button("üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–ª—è –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤", type="primary", use_container_width=True):
            with st.spinner("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ –∏ –¥–µ–ª–∞—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ..."):
                try:
                    if ('pipeline_ready' in st.session_state and st.session_state['pipeline_ready'] and 
                        'use_simple_processing' not in st.session_state):
                        
                        st.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                        pipeline = st.session_state['pipeline']
                        processed_data, ids = preprocess_with_pipeline(df, pipeline)
                    else:
                        
                        st.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
                        processed_data, ids = preprocess_simple(df)
                    
                    if processed_data is None:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")
                        st.stop()
                    
                    st.write(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processed_data.shape[1]}")
                    
                    predictions = model.predict(processed_data)
                    
                    try:
                        predictions = np.expm1(predictions)
                        st.info("‚ÑπÔ∏è –ü—Ä–∏–º–µ–Ω–µ–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: expm1 (log1p ‚Üí –¥–æ–ª–ª–∞—Ä—ã)")
                    except:
                        st.info("‚ÑπÔ∏è –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É–∂–µ –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö")
                    
                    results_df = pd.DataFrame({
                        'Id': ids,
                        'Predicted_Price': predictions
                    })
                    
                    st.markdown("<h2 class='section-header'>üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</h2>", unsafe_allow_html=True)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("–û–±—ä–µ–∫—Ç–æ–≤", len(predictions))
                    col2.metric("–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞", f"${predictions.mean():,.0f}")
                    col3.metric("–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è", f"${predictions.min():,.0f}")
                    col4.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è", f"${predictions.max():,.0f}")
                    
                    if len(predictions) > 1:
                        st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω")
                        st.bar_chart(results_df.set_index('Id')['Predicted_Price'])
                        
                        if predictions.std() < 50000:
                            st.warning(f"‚ö†Ô∏è –¶–µ–Ω—ã —Å–ª–∏—à–∫–æ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã–µ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: ${predictions.std():,.0f})")
                    
                    st.subheader("üìã –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
                    st.dataframe(
                        results_df.style.format({'Predicted_Price': '${:,.0f}'}),
                        height=400,
                        use_container_width=True
                    )
                    
                    csv = results_df.to_csv(index=False)
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (CSV)",
                        data=csv,
                        file_name=f"house_price_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True,
                        type="primary"
                    )
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {str(e)}")
                    st.info("‚ÑπÔ∏è –í–æ–∑–º–æ–∂–Ω–æ, –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
                    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

